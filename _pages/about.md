---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
# ğŸ˜€About Me

Hello! I'm Dongchen Liu. Welcome to my homepage. I'm a third-year undergraduate student of Tsinghua University, currently seeking reasearch mentorship for future research! 

My research interest includes machine learning and computer vision. (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=tHxnJqcAAAAJ&hl=en&authuser=1'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).

<span class='anchor' id='educations'></span>
# ğŸ“– Educations
- *2023 - now*, Department of Automation, Tsinghua University(Expected: Jun 2027)

<span class='anchor' id='news'></span>
# ğŸ”¥ News
- *2026.02*: &nbsp;ğŸ‰ğŸ‰ My first publication is coming soon...

<span class='anchor' id='publications'></span>
# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv</div><img src='images/papers/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[GameVerse]()

Zhangkuan\*, **Dongchen Liu**\*, Qiyue Zhao,Jinkun Hou,Xinran Zhang,Qinlei Xie,Miao Liu,Yiming Li<sup>â€ </sup>

[**Project**]() <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
<!-- - Human gameplay is a visually grounded interaction loop in which players act, reflect on failures, and watch tutorials to refine strategies. Can Vision-Language Models (VLMs) also learn from video-based reflection?  We present \textbf{GameVerse}, a comprehensive video game benchmark that enables a \textit{reflective visual interaction loop}. Moving beyond traditional \textit{\textbf{fire-and-forget}} evaluations, it uses a novel \textit{\textbf{reflect-and-retry}} paradigm to assess how VLMs internalize visual experience and improve policies. To facilitate systematic and scalable evaluation, we also introduce a \textit{cognitive hierarchical taxonomy} spanning 15 globally popular games, \textit{dual action space} for both semantic and GUI control, and \textit{milestone evaluation} using advanced VLMs to quantify progress. Our experiments show that VLMs benefit from video-based reflection in varied settings, and perform best by combining failure trajectories and expert tutorialsâ€”a \textit{training-free} analogue to reinforcement learning (RL) plus supervised fine-tuning (SFT). -->
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

<span class='anchor' id='honors-and-awards'></span>
# ğŸ– Honors and Awards
- *2023-2025* Winning Comprehensive Excellence Scholarship, Tsinghua University in a row. 

<span class='anchor' id='projects'></span>
# ğŸ”¨ Projects

## The 4th Tsinghua University Cyberdog Development Competition

- Implemented cooperative soccer offense/defense for two quadruped robots based on ROS 2.
- Awarded Third Prize (ranked 8/19).

## THUAI 7, Tsinghua University

- Wrote the C++ codebase for an agent in a competitive game environment.
- Awarded Second Prize (ranked 3/34).

<span class='anchor' id='society'></span>
# ğŸ¤µ Society

- Staff Member, Software Section, Student Association for Science and Technology, Department of Automation, Tsinghua University (2024â€“2025)

